# debug mode
debug = false

# base configuration directory (typically you won't change this!)
home_dir = "~/.prefect"

backend = "cloud"

[server]
host = "http://localhost"
port = "4200"
host_port = "4200"
host_ip = "127.0.0.1"
endpoint = "${server.host}:${server.port}"

    [server.database]
    host = "localhost"
    port = "5432"
    host_port = "5432"
    name = "prefect_server"
    username = "prefect"
    # set to "" to generate a random password each time the database starts
    password = "test-password"
    connection_url = "postgresql://${server.database.username}:${server.database.password}@${server.database.host}:${server.database.port}/${server.database.name}"
    volume_path = "${home_dir}/pg_data"

    [server.graphql]
    host = "0.0.0.0"
    port = "4201"
    host_port = "4201"
    debug = false
    path = "/graphql/"

    [server.hasura]
    host = "localhost"
    port = "3000"
    host_port = "3000"
    admin_secret = "" # a string. One will be automatically generated if not provided.
    claims_namespace = "hasura-claims"
    graphql_url = "http://${server.hasura.host}:${server.hasura.port}/v1alpha1/graphql"
    ws_url = "ws://${server.hasura.host}:${server.hasura.port}/v1alpha1/graphql"
    execute_retry_seconds = 10

    [server.ui]
    host = "http://localhost"
    port = "8080"
    host_port = "8080"
    host_ip = "127.0.0.1"
    endpoint = "${server.ui.host}:${server.ui.port}"
    apollo_url = "http://localhost:4200/graphql"

    [server.telemetry]
    enabled = true

[cloud]
api = "${${backend}.endpoint}"
endpoint = "https://api.prefect.io"
graphql = "${cloud.api}/graphql"
use_local_secrets = true
heartbeat_interval = 30.0
heartbeat_mode = "process" # ['process', 'thread', 'off']
check_cancellation_interval = 15.0
diagnostics = false
request_timeout = 15

# If set, logs for flow runs reporting to the API will be sent to the backend
send_flow_run_logs = true

# rate at which to batch upload logs
logging_heartbeat = 5

queue_interval = 30.0

# The API key to use for authentication. Generally, we recommend using `prefect auth login` instead
api_key = ""

# The tenant id to perform actions in when sending requests. Generally, we recommend using `prefect auth switch-tenants` instead
tenant_id = ""

    [cloud.agent]
    name = "agent"
    labels = "[]"

    # Set to `DEBUG` for verbose logging
    level = "INFO"

    # This configuration field is deprecated, use `cloud.api_key` instead.
    auth_token = ""

    # Internal address for agent health checks, etc...
    agent_address = ""

        [cloud.agent.resource_manager]
        # Separate loop interval for resource managers
        loop_interval = 60


[logging]
# The logging level: NOTSET, DEBUG, INFO, WARNING, ERROR, or CRITICAL
level = "INFO"

# The log format
format = "[%(asctime)s] %(levelname)s - %(name)s | %(message)s"

# additional log attributes to extract from context
# e.g., log_attributes = "['context_var']"
log_attributes = "[]"

# the timestamp format
datefmt = "%Y-%m-%d %H:%M:%S%z"

# Extra loggers for Prefect log configuration
extra_loggers = "[]"

[flows]
# If true, edges are checked for cycles as soon as they are added to the flow. If false,
# cycles are only checked when tasks are sorted (for example, when running or
# serializing the flow). Defaults to false because it can affect the performance of
# large flows.
eager_edge_validation = false
# If true, `flow.run` will run on schedule by default.
# If false, only a single execution will occur (no retries, etc.)
run_on_schedule = true
# If true, tasks which set `checkpoint=True` will have their result handlers called
checkpointing = false

    [flows.defaults]
        [flows.defaults.storage]
        # Whether to include a storage's default labels. Useful for
        # controlling Agent's workflows.
        add_default_labels = true
        # the default storage class, specified using a full path
        default_class = "prefect.storage.Local"

[tasks]

    [tasks.defaults]
    # the number of times tasks retry before they fail.
    # false indicates that tasks should never retry (equivalent to max_retries = 0)
    max_retries = false

    # the amount of time tasks should wait before retrying, in seconds.
    # false indicates that tasks have no default value (users must specify one to set it)
    retry_delay = false


[engine]

    [engine.executor]

    # the default executor, specified using a full path
    default_class = "prefect.executors.LocalExecutor"

        [engine.executor.dask]
        # the default scheduler address for the DaskExecutor.
        address = ""

        # the default Cluster class to use to create a temporary dask cluster
        cluster_class = "distributed.deploy.local.LocalCluster"

    [engine.flow_runner]
    # the default flow runner, specified using a full path
    default_class = "prefect.engine.flow_runner.FlowRunner"

    [engine.task_runner]
    # the default task runner, specified using a full path
    default_class = "prefect.engine.task_runner.TaskRunner"

---
title: Write and run tasks
description: Learn the basics of writing tasks.
---

A Prefect task is a Python function decorated with `@task` that represents a discrete unit of work in a 
Prefect workflow. Tasks can:

- Take inputs, perform work, and return outputs
- Cache their execution across invocations
- Encapsulate workflow logic into reusable units across flows and subflows
- Receive metadata about upstream task dependencies and their state before running
- Use automatic [logging](/3.0rc/develop/observe-workflows/logging/) to capture runtime details, tags, 
and final state
- Execute concurrently
- Be defined in the same file as the flow or imported from modules
- Be called from flows, subflows, or other tasks (Prefect 2.18+)

Flows and tasks share some common features:

- They can be defined using their respective decorator, which accepts configuration settings 
(see all [task settings](/3.0rc/develop/write-tasks/#task-arguments) and 
[flow settings](/3.0rc/develop/write-flows/#flow-settings))
- They can have a name, description, and tags for organization and bookkeeping
- They provide functionality for retries, timeouts, and other hooks to handle failure and completion events

## Example task

Here's an example of what it looks like to move a request from a flow into a task:

```python repo_info.py
import httpx
from prefect import flow, task
from typing import Optional


@task
def get_url(url: str, params: Optional[dict[str, any]] = None):
    response = httpx.get(url, params=params)
    response.raise_for_status()
    return response.json()


@flow(retries=3, retry_delay_seconds=5, log_prints=True)
def get_repo_info(repo_name: str = "PrefectHQ/prefect"):
    url = f"https://api.github.com/repos/{repo_name}"
    repo_stats = get_url(url)
    print(f"{repo_name} repository statistics ü§ì:")
    print(f"Stars üå† : {repo_stats['stargazers_count']}")
    print(f"Forks üç¥ : {repo_stats['forks_count']}")

if __name__ == "__main__":
    get_repo_info()
```

Running that flow in the terminal results in something like this:

```bash
09:55:55.412 | INFO    | prefect.engine - Created flow run 'great-ammonite' for flow 'get-repo-info'
09:55:55.499 | INFO    | Flow run 'great-ammonite' - Created task run 'get_url-0' for task 'get_url'
09:55:55.500 | INFO    | Flow run 'great-ammonite' - Executing 'get_url-0' immediately...
09:55:55.825 | INFO    | Task run 'get_url-0' - Finished in state Completed()
09:55:55.827 | INFO    | Flow run 'great-ammonite' - PrefectHQ/prefect repository statistics ü§ì:
09:55:55.827 | INFO    | Flow run 'great-ammonite' - Stars üå† : 12157
09:55:55.827 | INFO    | Flow run 'great-ammonite' - Forks üç¥ : 1251
09:55:55.849 | INFO    | Flow run 'great-ammonite' - Finished in state Completed('All states completed.')
```

This task run is tracked in the UI as well.

## Supported functions

Almost any standard Python function can be turned into a Prefect task by adding the `@task` decorator. 

<Tip>
Tasks are always executed in the main thread by default, unless a specific [task runner](/3.0rc/develop/write-tasks/use-task-runners) is used to execute them on different threads, processes, or infrastructure. This facilitates native Python debugging and profiling.
</Tip>

### Synchronous functions

The simplest Prefect task is a synchronous Python function. Here's an example of a synchronous task that prints a message:

```python
from prefect import task

@task
def print_message():
    print("Hello, I'm a task")

print_message()
```

### Asynchronous functions

Prefect also supports asynchronous Python functions. 
The resulting tasks are coroutines that can be awaited or run concurrently, following [standard async Python behavior](https://docs.python.org/3/library/asyncio-task.html).

```python
from prefect import task
import asyncio

@task
async def print_message():
    await asyncio.sleep(1)
    print("Hello, I'm an async task")

asyncio.run(print_message())
```

### Class Methods

Prefect supports snchronous and asynchronous methods as tasks, including instance methods, class methods, and static methods. For class methods and static methods, you must apply the appropriate method decorator _above_ the `@task` decorator:

```python
from prefect import task

class MyClass:

    @task
    def my_instance_method(self):
        pass

    @classmethod
    @task
    def my_class_method(cls):
        pass

    @staticmethod
    @task
    def my_static_method():
        pass

MyClass().my_instance_method()
MyClass.my_class_method()
MyClass.my_static_method()
```

### Generators

Prefect supports synchronous and asynchronous generators as tasks. The task is considered to be `Running` as long as the generator is yielding values. When the generator is exhausted, the task is considered `Completed`. Any values yielded by the generator can be consumed by other tasks, and they will automatically record the generator task as their parent. 

```python
from prefect import task

@task
def generator():
    for i in range(10):
        yield i

@task
def consumer(x):
    print(x)

for val in generator():
    consumer(val)
```

<Warning>
**Generator functions are consumed when returned from tasks**

The result of a completed task must be serializable, but generators cannot be serialized. 
Therefore, if you return a generator from a task, the generator will be fully consumed and its yielded values will be returned as a list. 
This can lead to unexpected behavior or blocking if the generator is infinite or very large.

Here is an example of proactive generator consumption:

```python
from prefect import task

def gen():
    yield from [1, 2, 3]
    print('Generator consumed!')

@task
def f():
    return gen()
    
f()  # prints 'Generator consumed!'
```

If you need to return a generator without consuming it, you can `yield` it instead of using `return`. 
Values yielded from generator tasks are not considered final results and do not face the same serialization constraints:

```python
from prefect import task

def gen():
    yield from [1, 2, 3]
    print('Generator consumed!')

@task
def f():
    yield gen()
    
generator = next(f())
list(generator) # prints 'Generator consumed!'

```
</Warning>

## Concurrency

Tasks enable concurrent execution, allowing you to execute multiple tasks asynchronously.
This concurrency can greatly enhance the efficiency and performance of your workflows.

Expand the script to calculate the average open issues per user by making more requests:

```python repo_info.py
import httpx
from datetime import timedelta
from prefect import flow, task
from prefect.tasks import task_input_hash
from typing import Optional


@task(cache_key_fn=task_input_hash, cache_expiration=timedelta(hours=1))
def get_url(url: str, params: Optional[dict[str, any]] = None):
    response = httpx.get(url, params=params)
    response.raise_for_status()
    return response.json()


def get_open_issues(repo_name: str, open_issues_count: int, per_page: int = 100):
    issues = []
    pages = range(1, -(open_issues_count // -per_page) + 1)
    for page in pages:
        issues.append(
            get_url(
                f"https://api.github.com/repos/{repo_name}/issues",
                params={"page": page, "per_page": per_page, "state": "open"},
            )
        )
    return [i for p in issues for i in p]


@flow(retries=3, retry_delay_seconds=5, log_prints=True)
def get_repo_info(repo_name: str = "PrefectHQ/prefect"):
    repo_stats = get_url(f"https://api.github.com/repos/{repo_name}")
    issues = get_open_issues(repo_name, repo_stats["open_issues_count"])
    issues_per_user = len(issues) / len(set([i["user"]["id"] for i in issues]))
    print(f"{repo_name} repository statistics ü§ì:")
    print(f"Stars üå† : {repo_stats['stargazers_count']}")
    print(f"Forks üç¥ : {repo_stats['forks_count']}")
    print(f"Average open issues per user üíå : {issues_per_user:.2f}")


if __name__ == "__main__":
    get_repo_info()

```

Now you're fetching the data you need, but the requests happen sequentially.
Tasks expose a [`submit`](/3.0rc/api-ref/prefect/tasks/#prefect.tasks.Task.submit) method that changes 
the execution from sequential to concurrent.
In this example, you also need to use the 
[`result`](/3.0rc/api-ref/prefect/futures/#prefect.futures.PrefectFuture.result) 
method to unpack a list of return values:

```python 
def get_open_issues(repo_name: str, open_issues_count: int, per_page: int = 100):
    issues = []
    pages = range(1, -(open_issues_count // -per_page) + 1)
    for page in pages:
        issues.append(
            get_url.submit(
                f"https://api.github.com/repos/{repo_name}/issues",
                params={"page": page, "per_page": per_page, "state": "open"},
            )
        )
    return [i for p in issues for i in p.result()]
```

The logs show that each task is running concurrently:


```bash
12:45:28.241 | INFO    | prefect.engine - Created flow run 'intrepid-coua' for flow 'get-repo-info'
12:45:28.311 | INFO    | Flow run 'intrepid-coua' - Created task run 'get_url-0' for task 'get_url'
12:45:28.312 | INFO    | Flow run 'intrepid-coua' - Executing 'get_url-0' immediately...
12:45:28.543 | INFO    | Task run 'get_url-0' - Finished in state Completed()
12:45:28.583 | INFO    | Flow run 'intrepid-coua' - Created task run 'get_url-1' for task 'get_url'
12:45:28.584 | INFO    | Flow run 'intrepid-coua' - Submitted task run 'get_url-1' for execution.
12:45:28.594 | INFO    | Flow run 'intrepid-coua' - Created task run 'get_url-2' for task 'get_url'
12:45:28.594 | INFO    | Flow run 'intrepid-coua' - Submitted task run 'get_url-2' for execution.
12:45:28.609 | INFO    | Flow run 'intrepid-coua' - Created task run 'get_url-4' for task 'get_url'
12:45:28.610 | INFO    | Flow run 'intrepid-coua' - Submitted task run 'get_url-4' for execution.
12:45:28.624 | INFO    | Flow run 'intrepid-coua' - Created task run 'get_url-5' for task 'get_url'
12:45:28.625 | INFO    | Flow run 'intrepid-coua' - Submitted task run 'get_url-5' for execution.
12:45:28.640 | INFO    | Flow run 'intrepid-coua' - Created task run 'get_url-6' for task 'get_url'
12:45:28.641 | INFO    | Flow run 'intrepid-coua' - Submitted task run 'get_url-6' for execution.
12:45:28.708 | INFO    | Flow run 'intrepid-coua' - Created task run 'get_url-3' for task 'get_url'
12:45:28.708 | INFO    | Flow run 'intrepid-coua' - Submitted task run 'get_url-3' for execution.
12:45:29.096 | INFO    | Task run 'get_url-6' - Finished in state Completed()
12:45:29.565 | INFO    | Task run 'get_url-2' - Finished in state Completed()
12:45:29.721 | INFO    | Task run 'get_url-5' - Finished in state Completed()
12:45:29.749 | INFO    | Task run 'get_url-4' - Finished in state Completed()
12:45:29.801 | INFO    | Task run 'get_url-3' - Finished in state Completed()
12:45:29.817 | INFO    | Task run 'get_url-1' - Finished in state Completed()
12:45:29.820 | INFO    | Flow run 'intrepid-coua' - PrefectHQ/prefect repository statistics ü§ì:
12:45:29.820 | INFO    | Flow run 'intrepid-coua' - Stars üå† : 12159
12:45:29.821 | INFO    | Flow run 'intrepid-coua' - Forks üç¥ : 1251
Average open issues per user üíå : 2.27
12:45:29.838 | INFO    | Flow run 'intrepid-coua' - Finished in state Completed('All states completed.')
```

**Call a task from a flow**

Use the `@task` decorator to designate a function as a task. Calling the task creates a new task run:

```python 
from prefect import flow, task

@task
def my_task():
    print("Hello, I'm a task")

@flow
def my_flow():
    my_task()
```

**Call a task from another task**

A task can be called from within another task:

```python
from prefect import task

@task
def my_task():
    print("Hello, I'm a task")

@task(log_prints=True)
def my_parent_task():
    my_task()
```

Tasks are uniquely identified by a task key, which is a hash composed of the task name, the fully-qualified 
name of the function, and any tags. If the task does not have a name specified, the name is derived from the 
task function.

<Note>
**How big should a task be?**

Prefect encourages "small tasks." Each one should represent a single logical step of your workflow. 
This allows Prefect to better contain task failures.

There's nothing stopping you from putting all of your code in a single task. However, if any line of 
code fails, the entire task fails and must be retried from the beginning. 
Avoid this by splitting the code into multiple dependent tasks.
</Note>

## Task configuration

Tasks allow for customization through optional arguments that can be provided to the [task decorator](/3.0rc/api-ref/prefect/tasks/#prefect.tasks.task).

| Argument              | Description                                                                                                                                                                                                             |
| --------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `name`                | An optional name for the task. If not provided, the name is inferred from the function name.                                                                                                                       |
| `description`         | An optional string description for the task. If not provided, the description is pulled from the docstring for the decorated function.                                                                             |
| `tags`                | An optional set of tags associated with runs of this task. These tags are combined with any tags defined by a `prefect.tags` context at task runtime.                                                             |
| `cache_key_fn`        | An optional callable that, given the task run context and call parameters, generates a string key. If the key matches a previous completed state, that state result is restored instead of running the task again. |
| `cache_expiration`    | An optional amount of time indicating how long cached states for this task are restorable; if not provided, cached states will never expire.                                                                      |
| `retries`             | An optional number of times to retry on task run failure.                                                                                                                                                               |
| `retry_delay_seconds` | An optional number of seconds to wait before retrying the task after failure. This is only applicable if `retries` is nonzero.                                                                                          |
| `log_prints`|An optional boolean indicating whether to log print statements. |

See all possible options in the [Python SDK API docs](/3.0rc/api-ref/prefect/tasks/#prefect.tasks.task).

For example, you can provide a `name` value for the task. Here's an example of the optional `description` argument 
as well:

```python 
@task(name="hello-task", 
      description="This task says hello.")
def my_task():
    print("Hello, I'm a task")
```

You can distinguish runs of this task by providing a `task_run_name`; this setting accepts a string 
that may contain templated references to the keyword arguments of your task. The name is 
formatted using Python's standard string formatting syntax:

```python
import datetime
from prefect import flow, task

@task(name="My Example Task", 
      description="An example task for a tutorial.",
      task_run_name="hello-{name}-on-{date:%A}")
def my_task(name, date):
    pass

@flow
def my_flow():
    # creates a run with a name like "hello-marvin-on-Thursday"
    my_task(name="marvin", date=datetime.datetime.now(datetime.timezone.utc))
```

Additionally this setting accepts a function that returns a string for the task run name:

```python
import datetime
from prefect import flow, task

def generate_task_name():
    date = datetime.datetime.now(datetime.timezone.utc)
    return f"{date:%A}-is-a-lovely-day"

@task(name="My Example Task",
      description="An example task for a tutorial.",
      task_run_name=generate_task_name)
def my_task(name):
    pass

@flow
def my_flow():
    # creates a run with a name like "Thursday-is-a-lovely-day"
    my_task(name="marvin")
```

If you need access to information about the task, use the `prefect.runtime` module. For example:

```python
from prefect import flow
from prefect.runtime import flow_run, task_run

def generate_task_name():
    flow_name = flow_run.flow_name
    task_name = task_run.task_name

    parameters = task_run.parameters
    name = parameters["name"]
    limit = parameters["limit"]

    return f"{flow_name}-{task_name}-with-{name}-and-{limit}"

@task(name="my-example-task",
      description="An example task for a tutorial.",
      task_run_name=generate_task_name)
def my_task(name: str, limit: int = 100):
    pass

@flow
def my_flow(name: str):
    # creates a run with a name like "my-flow-my-example-task-with-marvin-and-100"
    my_task(name="marvin")
```

## Tags

Tags are optional string labels that enable you to identify and group tasks other than by name or flow. 
Tags are useful to:

- Filter task runs by tag in the UI and through the [Prefect REST API](/3.0rc/api-ref/rest-api/#filtering).
- Set [concurrency limits](#task-run-concurrency-limits) on task runs by tag.

You may specify tags as a keyword argument on the [task decorator](/3.0rc/api-ref/prefect/tasks/#prefect.tasks.task).

```python 
@task(name="hello-task", tags=["test"])
def my_task():
    print("Hello, I'm a task")
```

You can also provide tags as an argument with a 
[`tags` context manager](/3.0rc/api-ref/prefect/context/#prefect.context.tags), 
specifying tags when the task is called rather than in its definition.

```python 
from prefect import flow, task
from prefect import tags

@task
def my_task():
    print("Hello, I'm a task")

@flow
def my_flow():
    with tags("test"):
        my_task()
```

## Caching

Caching refers to the ability of a task run to enter a `Completed` state and return a predetermined 
value without actually running the code that defines the task. 
This allows you to efficiently reuse results of tasks that may be expensive to compute
and ensure that your pipelines are idempotent when retrying them due to unexpected failure. 

By default Prefect's caching logic is based on the following attributes of a task invocation:
- the inputs provided to the task
- the code definition of the task
- the prevailing flow run ID, or if executed autonomously, the prevailing task run ID

All of these are hashed to compute the task's _cache key_. 
This implies that, by default, calling the same task with the same inputs more than once within a flow 
will result in cached behavior for all calls after the first.
This behavior can be configured - see [customizing the cache](/3.0rc/develop/write-tasks/index#customizing-the-cache) below.

### Cache keys

To determine whether a task run should retrieve a cached state, Prefect uses the concept of a "cache key". 
A cache key is a computed string value that determines where the task's return value will be persisted within
its configured result storage.
When a task run begins, Prefect first computes its cache key and uses this to lookup a record in the task's result
storage. 
If an unexpired record is found, this result is returned and the task does not run but instead enters a 
`Cached` state with the corresponding result value.

Cache keys can be shared by the same task across different flows, and even among different tasks, 
so long as they all share a common result storage location.

By default Prefect stores results locally in `~/.prefect/storage/`. 
The filenames in this directory will correspond exactly to computed cache keys from your task runs.

<Warning>
**Relationship with result persistence** 

Task caching and result persistence are intimately related. Because task caching relies on loading a 
known result, task caching will only work when your task can persist its output 
to a fixed and known location.

Therefore any configuration which explicitly avoids result persistence will result in your task never
using a cache, for example setting `persist_result=False`.
</Warning>

### Cache policies

Cache key computation can be configured through the use of _cache policies_. 
A cache policy is a recipe for computing cache keys for a given task.

Prefect comes prepackaged with a few common cache policies:
- `DEFAULT`: this cache policy uses the task's inputs, it's code definition, as well as the prevailing flow run ID
to compute the task's cache key.
- `INPUTS`: this cache policy uses _only_ the task's inputs to compute the cache key.
- `TASK_SOURCE`: this cache policy uses _only_ the task's code definition to compute the cache key.
- `FLOW_PARAMETERS`: this cache policy uses _only_ the parameter values provided to the parent flow run
to compute the cache key.
- `NONE`: this cache policy always returns `None` and therefore avoids caching and result persistence altogether

These can be set using the `cache_policy` keyword on the [task decorator](/3.0rc/api-ref/prefect/tasks/#prefect.tasks.task):

```python
from prefect import task
from prefect.cache_policies import TASK_SOURCE

import time


@task(cache_policy=TASK_SOURCE)
def my_stateful_task():
    print('sleeping')
    time.sleep(10)
    return 42

my_stateful_task() # sleeps
my_stateful_task() # does not sleep
```

No matter how many flows call it, this task will run once and only once until its underlying code is altered:

```python
@task(cache_policy=TASK_SOURCE)
def my_stateful_task():
    print('sleeping')
    time.sleep(10)

    # change the return value, for example
    return 43 

my_stateful_task() # sleeps again
```

### Customizing the cache

Prefect allows users to configure task caching behavior in numerous ways.

#### Cache expiration

All cache keys can optionally be given an _expiration_ through the `cache_expiration` keyword on 
the [task decorator](/3.0rc/api-ref/prefect/tasks/#prefect.tasks.task):
This keyword accepts a `datetime.timedelta` specifying a duration for which the cached value should be
considered valid.

Providing an expiration value results in Prefect persisting an expiration timestamp alongside the result
record for the task.
This expiration is then applied to _all_ other tasks that may share this cache key.

#### Cache policies

Cache policies can be composed and altered using basic Python syntax to form more complex policies.
For example, all task policies except for `NONE` can be _added_ together to form new policies that combine
the individual policies' logic into a larger cache key computation.
Combining policies in this way therefore results in caches that are _easier_ to bust.

For example:

```python
from prefect import task
from prefect.cache_policies import TASK_SOURCE, INPUTS

@task(cache_policy=TASK_SOURCE + INPUTS)
def my_cached_task(x: int):
    return x + 42
```

This task will rerun anytime you provide new values for `x`, _or_ anytime you change the underlying code.

The `INPUTS` policy is a special policy that allows you to _subtract_ string values to signal ignoring
certain task inputs:

```python
from prefect import task
from prefect.cache_policies import INPUTS


my_custom_policy = INPUTS - 'debug'

@task(cache_policy=my_custom_policy)
def my_cached_task(x: int, debug: bool = False):
    print('running...')
    return x + 42


my_cached_task(1)
my_cached_task(1, debug=True) # still uses the cache
```

#### Cache key functions

Users can configure custom cache policy logic through the use of cache key functions.
A cache key function is a function that accepts two positional arguments:
- The first argument corresponds to the `TaskRunContext`, which stores task run metadata. For example, 
this object has attributes `task_run_id`, `flow_run_id`, and `task`, all of which can be used in your
custom logic.
- The second argument corresponds to a dictionary of input values to the task. For example, 
if your task has the signature `fn(x, y, z)` then the dictionary will have keys "x", "y", and "z" with corresponding values that can be used to compute your cache key.

This function can then be specified using the `cache_key_fn` argument on 
the [task decorator](/3.0rc/api-ref/prefect/tasks/#prefect.tasks.task).

For example:

```python
def static_cache_key(context, parameters):
    # return a constant
    return "static cache key"


@task(cache_key_fn=static_cache_key)
def my_cached_task(x: int):
    return x + 1
```

### Caching example

In this example, until the `cache_expiration` time ends, as long as the input to `hello_task()` remains 
the same when it is called, the cached return value is returned. In this situation the task is not rerun. 
However, if the input argument value changes, `hello_task()` runs using the new input.

```python 
from datetime import timedelta
from prefect import flow, task
from prefect.cache_policies import INPUTS

@task(cache_policy=INPUTS, cache_expiration=timedelta(days=1))
def hello_task(name_input):
    # Doing some work
    print("Saying hello")
    return "hello " + name_input

@flow(log_prints=True)
def hello_flow(name_input):
    hello_task(name_input)
    hello_task(name_input) # does not rerun
```

A more realistic example might include the flow run id in the cache key, so only repeated 
calls in the same flow run are cached:

```python
from prefect.cache_policies import INPUTS, FLOW_RUN_ID


@task(cache_policy=INPUTS + FLOW_RUN_ID, cache_expiration=timedelta(days=1))
def hello_task(name_input):
    # Doing some work
    print("Saying hello")
    return "hello " + name_input


@flow(log_prints=True)
def hello_flow(name_input):
    # reruns each time the flow is run
    hello_task(name_input) 

    # but the same call within the same flow run is Cached
    hello_task(name_input) 
```

### Force ignore the cache

A cache "refresh" instructs Prefect to ignore the data associated with a task's cache key and rerun 
no matter what.

The `refresh_cache` option enables this behavior for a specific task:

```python
import random


def static_cache_key(context, parameters):
    # return a constant
    return "static cache key"


@task(cache_key_fn=static_cache_key, refresh_cache=True)
def caching_task():
    return random.random()
```

When this task runs, it _always_ updates the cache key instead of using the cached value. This is 
particularly useful when you have a flow that is responsible for updating the cache.

To refresh the cache for all tasks, use the `PREFECT_TASKS_REFRESH_CACHE` setting. 
Setting `PREFECT_TASKS_REFRESH_CACHE=true` changes the default behavior of all tasks to refresh. 
This is particularly useful to rerun a flow without cached results.

If you have tasks that should not refresh when this setting is enabled, you may explicitly set `refresh_cache` 
to `False`. These tasks will never refresh the cache. If a cache key exists it will be read, not updated. 
If a cache key does _not_ exist yet, these tasks can still write to the cache.

```python
@task(cache_key_fn=static_cache_key, refresh_cache=False)
def caching_task():
    return random.random()
```

## Timeouts

Task timeouts prevent unintentional long-running tasks. When the duration of execution for a 
task exceeds the duration specified in the timeout, a timeout exception is raised and the task is  
marked as failed. In the UI, the task is visibly designated as `TimedOut`. From the perspective of the 
flow, the timed-out task is treated like any other failed task.

Specify timeout durations with the `timeout_seconds` keyword argument:

```python 
from prefect import task
import time

@task(timeout_seconds=1, log_prints=True)
def show_timeouts():
    print("I will execute")
    time.sleep(5)
    print("I will not execute")
```

## Task results

Depending on how you call tasks, they can return different types of results and optionally engage the use of 
a [task runner](/3.0rc/develop/write-tasks/use-task-runners/).

Any task can return:

- Data‚Ää, such as `int`, `str`, `dict`, `list`. This is the default behavior any time you 
call `your_task()`.
- [`PrefectFuture`](/3.0rc/api-ref/prefect/futures/#prefect.futures.PrefectFuture). This is achieved 
by calling [`your_task.submit()`](/3.0rc/develop/write-tasks/use-task-runners/#using-a-task-runner). 
A `PrefectFuture` contains both _data_ and _State_.
- Prefect [`State`](/3.0rc/api-ref/server/schemas/states/). Anytime you call your task or flow with 
the argument `return_state=True`, it directly returns a state to build custom behavior based 
on a state change you care about, such as task or flow failing or retrying.

To run your task with a [task runner](/3.0rc/develop/write-tasks/use-task-runners/), you must call the task 
with `.submit()`.

See [state returned values](/3.0rc/develop/write-tasks/use-task-runners/#using-results-from-submitted-tasks) 
for examples.

<Tip>
**Task runners are optional**

If you just need the result from a task, call the task from your flow. For most workflows, 
the default behavior of calling a task directly and receiving a result is enough.
</Tip>

## Wait for

To create a dependency between two tasks that do not exchange data, but one needs to wait for the other to 
finish, use the special [`wait_for`](/3.0rc/api-ref/prefect/tasks/#prefect.tasks.Task.submit) keyword argument:

```python
@task
def task_1():
    pass

@task
def task_2():
    pass

@flow
def my_flow():
    x = task_1()

    # task 2 will wait for task_1 to complete
    y = task_2(wait_for=[x])
```

## Map

Prefect provides a `.map()` implementation that automatically creates a task run for each element of its 
input data. Mapped tasks represent the computations of many individual children tasks.

The simplest Prefect map takes a task and applies it to each element of its inputs.

```python
from prefect import flow, task

@task
def print_nums(nums):
    for n in nums:
        print(n)

@task
def square_num(num):
    return num**2

@flow
def map_flow(nums):
    print_nums(nums)
    squared_nums = square_num.map(nums) 
    print_nums(squared_nums)

map_flow([1,2,3,5,8,13])
```

Prefect also supports `unmapped` arguments, allowing you to pass static values that don't get mapped over.

```python
from prefect import flow, task

@task
def add_together(x, y):
    return x + y

@flow
def sum_it(numbers, static_value):
    futures = add_together.map(numbers, static_value)
    return futures

sum_it([1, 2, 3], 5)
```

If your static argument is an iterable, wrap it with `unmapped` to tell Prefect to treat it 
as a static value.

```python
from prefect import flow, task, unmapped

@task
def sum_plus(x, static_iterable):
    return x + sum(static_iterable)

@flow
def sum_it(numbers, static_iterable):
    futures = sum_plus.map(numbers, static_iterable)
    return futures

sum_it([4, 5, 6], unmapped([1, 2, 3]))
```

---
title: Deploying Flows
description: Learn how Prefect flow deployments enable configuring flows for scheduled and remote execution.
tags:
    - orchestration
    - flow runs
    - deployments
    - schedules
    - triggers
    - tutorial
search:
  boost: 2
---

<Note>
    ** Reminder to connect to Prefect Cloud or a self-hosted Prefect server instance**
    
    Some features in this tutorial, such as scheduling, require you to connect to a Prefect server.
    If using a self-hosted setup, run `prefect server start` to run both the webserver and UI.
    If using Prefect Cloud, make sure you have [successfully authenticated your local environment](/cloud/cloud-quickstart/).

</Note>
## About deployments

[Deployments](/concepts/deployments/) are server-side representations of flows. They store the crucial metadata needed for remote orchestration including when, where, and how a workflow should run.

Attributes of a deployment include:

- __Flow entrypoint__: path to your flow function
- __Schedule__ or __Trigger__: optional schedule or triggering rules for this deployment
- __Tags__: optional text labels for organizing your deployments

Some of the most common reasons to use an orchestration tool like Prefect are for [scheduling](/concepts/schedules/) and [event-based triggering](/concepts/automations/).
As opposed to manually triggering and managing flow runs, deploying a flow exposes an API and UI that allow you to:

- trigger new runs, [cancel active runs](/concepts/flows/#cancel-a-flow-run), pause scheduled runs, customize parameters, and more
- remotely configure schedules and automation rules for your deployments
- dynamically provision infrastructure using [workers](/tutorials/workers/)

## Create a deployment

Continuing with the `get_repo_info` flow from the previous section, create a deployment by calling a single method on the flow object: `flow.serve`.

```python hl_lines="16-17" title="repo_info.py"
import httpx
from prefect import flow


@flow(log_prints=True)
def get_repo_info(repo_name: str = "PrefectHQ/prefect"):
    url = f"https://api.github.com/repos/{repo_name}"
    response = httpx.get(url)
    response.raise_for_status()
    repo = response.json()
    print(f"{repo_name} repository statistics ü§ì:")
    print(f"Stars üå† : {repo['stargazers_count']}")
    print(f"Forks üç¥ : {repo['forks_count']}")


if __name__ == "__main__":
    get_repo_info.serve(name="my-first-deployment")
```

Running this script will:

- create a deployment called ```my-first-deployment``` for your flow in the Prefect API
- continue running to listen for flow runs for this deployment; when a run is found, it will *asynchronously execute within a subprocess*

<Warning>
    **You must define deployments in static files**

    You can define and run flows interactively, within REPLs or Notebooks.
    However, deployments require that your flow definition exist in a known file.  
</Warning>


Because this deployment has no schedule or triggering automation, you must use the UI or API to create runs for it.
Use the CLI (in a separate terminal window) to create a run for this deployment:

```bash
prefect deployment run 'get-repo-info/my-first-deployment'
```

In your terminal or UI, you should see the newly created run execute successfully.  
Next, add a schedule and additional metadata.

### Additional options

The `serve` method on flows exposes many options for the deployment.
Here's how to use some of those options:

- `cron`: a keyword that allows you to set a cron string schedule for the deployment; see [schedules](/concepts/schedules/) for more advanced scheduling options
- `tags`: a keyword that allows you to tag this deployment and its runs for bookkeeping and filtering purposes
- `description`: a keyword that allows you to document what this deployment does; by default the description is set from the docstring of the flow function (if documented)
- `version`: a keyword that allows you to track changes to your deployment; uses a hash of the file containing the flow by default; popular options include semver tags or git commit hashes

Next, add these options to your deployment:

```python
if __name__ == "__main__":
    get_repo_info.serve(
        name="my-first-deployment",
        cron="* * * * *",
        tags=["testing", "tutorial"],
        description="Given a GitHub repository, logs repository statistics for that repo.",
        version="tutorial/deployments",
    )
```

When you rerun this script, you will find an updated deployment in the UI that is actively scheduling work.  
Stop the script in the CLI using `CTRL+C` and your schedule automatically pauses.

!!! note "`.serve` is a long-running process"
    To execute remotely triggered or scheduled runs, your script with `flow.serve` must be actively running.

## Run multiple deployments at once

This method is useful for creating deployments for single flows. For two or more flows, you must provide a few additional method calls and imports:

```python hl_lines="2 18-20" title="multi_flow_deployment.py"
import time
from prefect import flow, serve


@flow
def slow_flow(sleep: int = 60):
    "Sleepy flow - sleeps the provided amount of time (in seconds)."
    time.sleep(sleep)


@flow
def fast_flow():
    "Fastest flow this side of the Mississippi."
    return


if __name__ == "__main__":
    slow_deploy = slow_flow.to_deployment(name="sleeper", interval=45)
    fast_deploy = fast_flow.to_deployment(name="fast")
    serve(slow_deploy, fast_deploy)
```

A few things to note:

- the `flow.to_deployment` interface exposes the *exact same* options as `flow.serve`; this method produces a deployment object
- the deployments are only registered with the API once `serve(...)` is called
- when serving multiple deployments, the only requirement is that they share a Python environment; they can be executed and scheduled independently of each other

A few optional steps for exploration include:

- pause and unpause the schedule for the "sleeper" deployment
- use the UI to submit ad-hoc runs for the "sleeper" deployment with different values for `sleep`
- cancel an active run for the "sleeper" deployment from the UI

<Tip>
    **Hybrid execution option**
    
    Another implication of Prefect's deployment interface is that you can choose to use our hybrid execution model.
    Whether you use Prefect Cloud or host a Prefect server instance, you can run workflows in the environments best suited to their execution.
    This model enables efficient use of your infrastructure resources while maintaining the privacy of your code and data.
    There is no ingress required.
    For more information [read more about our hybrid model](https://www.prefect.io/security/overview/#hybrid-model).
</Tip>

## Next steps

Deploying flows through the `serve` method is a fast way to start scheduling flows with Prefect.
However, if your team has more complex infrastructure requirements or you'd like to have Prefect manage flow execution, you can deploy flows to a work pool.

Learn about work pools and how Prefect Cloud can handle infrastructure configuration for you in the [next step of the tutorial](/tutorial/work-pools/).
---
title: Workers
description: Learn how flow deployments enable configuring flows for scheduled and remote execution with workers.
---

## Prerequisites

[Docker](https://docs.docker.com/engine/install/) installed and running on your machine.

## About workers

Work pools that rely on client-side workers enable you to run work flows in your own Docker containers, Kubernetes clusters, 
and serverless environments such as AWS ECS, Azure Container Instances, and GCP Cloud Run.

The following diagram summarizes the architecture of a worker-based work pool deployment:

```mermaid
graph TD
    subgraph your_infra["Your Execution Environment"]
        worker["Worker"]
    subgraph flow_run_infra[Flow Run Infra]
     flow_run_a(("Flow Run A"))
    end
    subgraph flow_run_infra_2[Flow Run Infra]
     flow_run_b(("Flow Run B"))
    end      
    end

    subgraph api["Prefect API"]
    Deployment --> |assigned to| work_pool
        work_pool(["Work Pool"])
    end

    worker --> |polls| work_pool
    worker --> |creates| flow_run_infra
    worker --> |creates| flow_run_infra_2
```

<Tip>
Notice above that the worker is in charge of provisioning the _flow run infrastructure_.
In the context of this tutorial, that flow run infrastructure is an ephemeral Docker container to host each flow run.
Different [worker types](/3.0rc/deploy/work-pools/control-runs/#worker-types) create different types of flow run 
infrastructure.
</Tip>

Next, create a work pool and worker to deploy your tutorial flow. You will execute it later with the Prefect API.

## Set up a work pool and worker

In this guide you will create a **Docker** type work pool through the CLI.

When you set the work pool type to **Docker**, the worker uses an available Docker 
client to execute all work sent to this pool inside a dedicated Docker container.

<Tip>
**Other work pool types**

There are [work pool types](/3.0rc/deploy/work-pools/control-runs/#worker-types) for serverless computing 
environments such as AWS ECS, Azure Container Instances, Google Cloud Run, and Vertex AI.
Kubernetes is also a popular work pool type.
</Tip>

### Create a work pool

To set up a **Docker** type work pool, run:


```bash
prefect work-pool create --type docker my-docker-pool
```


To confirm the work pool creation was successful, run:


```bash
prefect work-pool ls
```

You should see your new `my-docker-pool` listed in the output.

Next, check that you can see this work pool in your Prefect UI.

Navigate to the **Work Pools** tab and verify that you see `my-docker-pool` listed.

When you click into `my-docker-pool`, you should see a red status icon signifying that this work pool is not ready.

To make the work pool ready, start a worker.

### Start a worker

Workers are a lightweight polling process that kick off scheduled flow runs on a specific type of infrastructure (such as Docker).
To start a worker on your local machine, open a new terminal and confirm that your virtual environment has `prefect` installed.

Run the following command in this new terminal to start the worker:


```bash
prefect worker start --pool my-docker-pool

```

You should see the worker start.
It's now polling the Prefect API to check for any scheduled flow runs it should pick up and then submit for execution.
You‚Äôll see your new worker listed in the UI under the **Workers** tab of the Work Pools page with a recent last polled date.

You should now see a `Ready` status indicator on your work pool.

Keep this terminal session active for the worker to continue to pick up jobs.
Since you are running this worker locally, the worker will terminate if you close the terminal.
In a production setting this worker should run as a [daemonized or managed process](/3.0rc/deploy/dynamic-infra/push-runs-remote/).

Next, deploy your tutorial flow to `my-docker-pool`.

## Create the deployment

From the previous steps, you now have:

1. [A flow](/3.0rc/develop/write-flows/)
2. A work pool
3. A worker

Update your `repo_info.py` file to build a Docker image, and update your deployment so your worker can execute it.

Make the following updates in `repo_info.py`:

1. Change `flow.serve` to `flow.deploy`.
2. Tell `flow.deploy` which work pool to deploy to.
3. Tell `flow.deploy` the name for the Docker image to build.

The updated `repo_info.py` looks like this:

```python repo_info.py
import httpx
from prefect import flow


@flow(log_prints=True)
def get_repo_info(repo_name: str = "PrefectHQ/prefect"):
    url = f"https://api.github.com/repos/{repo_name}"
    response = httpx.get(url)
    response.raise_for_status()
    repo = response.json()
    print(f"{repo_name} repository statistics ü§ì:")
    print(f"Stars üå† : {repo['stargazers_count']}")
    print(f"Forks üç¥ : {repo['forks_count']}")


if __name__ == "__main__":
    get_repo_info.deploy(
        name="my-first-deployment", 
        work_pool_name="my-docker-pool", 
        image="my-first-deployment-image:tutorial",
        push=False
    )
```

<Note>
**Why the `push=False`?**

For this tutorial, your Docker worker is running on your machine, so you don't need to push the image built by 
`flow.deploy` to a registry. When your worker is running on a remote machine, you must push the image to a registry 
that the worker can access.

Remove the `push=False` argument, include your registry name, and ensure you've 
[authenticated with the Docker CLI](https://docs.docker.com/engine/reference/commandline/login/) to push the image to a registry.

</Note>

Now that you've updated your script, run it to deploy your flow to the work pool:

```bash
python repo_info.py
```
    
Prefect builds a custom Docker image containing your flow code. The worker can use it to dynamically spawn Docker 
containers whenever this workflow needs to run.

<Note>
    **Dockerfile**
    
    In this example, Prefect generates a Dockerfile that builds an image based on one of Prefect's published images. 
    The generated Dockerfile copies the current directory into the Docker image and installs any dependencies listed in a 
    `requirements.txt` file.

    To use a custom Dockerfile, specify the path to the Dockerfile using the `DockerImage` class:

    ```python repo_info.py
    import httpx
    from prefect import flow
    from prefect.docker import DockerImage


    @flow(log_prints=True)
    def get_repo_info(repo_name: str = "PrefectHQ/prefect"):
        url = f"https://api.github.com/repos/{repo_name}"
        response = httpx.get(url)
        response.raise_for_status()
        repo = response.json()
        print(f"{repo_name} repository statistics ü§ì:")
        print(f"Stars üå† : {repo['stargazers_count']}")
        print(f"Forks üç¥ : {repo['forks_count']}")


    if __name__ == "__main__":
        get_repo_info.deploy(
            name="my-first-deployment", 
            work_pool_name="my-docker-pool", 
            image=DockerImage(
                name="my-first-deployment-image",
                tag="tutorial",
                dockerfile="Dockerfile"
            ),
            push=False
        )
    ```
</Note>

### Modify the deployment

To update your deployment, modify your script and rerun it. Specify a value for `job_variables` 
so your Docker worker can successfully execute scheduled runs for this flow. See the example below.

The `job_variables` section allows you to fine-tune the infrastructure settings for a specific deployment. These values override 
default values in the specified work pool's [base job template](/3.0rc/deploy/work-pools/control-runs/#base-job-template).

When testing images locally without pushing them to a registry (to avoid potential errors like docker.errors.NotFound), 
we recommend including an `image_pull_policy` job_variable set to `Never`. However, for production workflows, push images to a 
remote registry for more reliability and accessibility.

Set the `image_pull_policy` as `Never` for this test deployment without affecting the default value set on your work pool:

```python repo_info.py
import httpx
from prefect import flow


@flow(log_prints=True)
def get_repo_info(repo_name: str = "PrefectHQ/prefect"):
    url = f"https://api.github.com/repos/{repo_name}"
    response = httpx.get(url)
    response.raise_for_status()
    repo = response.json()
    print(f"{repo_name} repository statistics ü§ì:")
    print(f"Stars üå† : {repo['stargazers_count']}")
    print(f"Forks üç¥ : {repo['forks_count']}")


if __name__ == "__main__":
    get_repo_info.deploy(
        name="my-first-deployment", 
        work_pool_name="my-docker-pool", 
        job_variables={"image_pull_policy": "Never"},
        image="my-first-deployment-image:tutorial",
        push=False
    )
```

To register this update to your deployment's parameters with Prefect's API, run:


```bash
python repo_info.py
```


Submit a flow-run to the work pool:


```bash
prefect deployment run 'get_repo_info/my-deployment'
```


<Warning>
    **Common Pitfall**
    
    Store and run your deploy scripts at the **root of your repo**, otherwise the built Docker file may be missing files that 
    it needs to execute.
</Warning>

<Tip>
    **Multiple deployments**
    
    A Prefect flow can have more than one deployment. 
    This pattern is useful for a flow to run in different execution environments.
</Tip>

## Learn more

- Learn how to configure deployments in YAML with [`prefect.yaml`](/3.0rc/deploy/work-pools/prefect-deploy/).
- [Deploy flows on Kubernetes](/3.0rc/deploy/dynamic-infra/deploy-kubernetes/)
- [Deploy flows in Docker](/3.0rc/deploy/dynamic-infra/deploy-docker/)
- [Deploy flows on serverless infrastructure](/3.0rc/deploy/dynamic-infra/push-runs-remote/)
- [Daemonize workers](/3.0rc/deploy/dynamic-infra/push-runs-remote/)

# Run deployments on serverless infrastructure with Prefect workers

Prefect provides hybrid work pools for workers to run flows on the serverless platforms of major cloud providers.
The following options are available:

- AWS Elastic Container Service (ECS)
- Azure Container Instances (ACI)
- Google Cloud Run
- Google Cloud Run V2
- Google Vertex AI

![Work pool options](/3.0rc/img/ui/work-pools.png)

- Create a work pool that sends work to your chosen serverless infrastructure
- Deploy a flow to that work pool
- Start a worker in your serverless cloud provider that polls its matched work pool for scheduled runs
- Schedule a deployment run that a worker picks up from the work pool and runs on your serverless infrastructure

<Note>
**Push work pools don't require a worker**

Options for push work pool versions of AWS ECS, Azure Container Instances, and Google Cloud Run that do not require a 
worker are available with Prefect Cloud.
These push work pool options require connection configuration information to be stored on Prefect Cloud.
Read more in the [Serverless push work pool guide](/3.0rc/deploy/dynamic-infra/push-runs-serverless/).
</Note>

This is a brief overview of the options to run workflows on serverless infrastructure.
For in-depth guides, see the Prefect integration libraries:

- [AWS ECS guide in the `prefect-aws` docs](https://prefecthq.github.io/prefect-aws/ecs_guide/)
- [Azure Container Instances guide](/integrations/prefect-azure/aci_worker/)
- [Google Cloud Run guide in the `prefect-gcp` docs](https://prefecthq.github.io/prefect-gcp/gcp-worker-guide/).
- For Google Vertex AI, follow the Cloud Run guide, substituting *Google Vertex AI* where *Google Cloud Run* is mentioned.

<Note>
**Choosing between Google Cloud Run and Google Vertex AI**

Google Vertex AI is well-suited for machine learning model training applications with GPUs or TPUs and high resource 
levels.
</Note>

## Steps

1. Make sure you have a user or service account on your chosen cloud provider with the necessary permissions to run serverless jobs
1. Create the appropriate serverless work pool that uses a worker in the Prefect UI
1. Create a deployment that references the work pool
1. Start a worker in your chose serverless cloud provider infrastructure
1. Run the deployment

## Next steps

Learn more about [workers and work pools](/3.0rc/deploy/work-pools/control-runs/).

Learn about installing dependencies at runtime or baking them into your Docker image in the 
[work pools and workers guide](/3.0rc/deploy/work-pools/prefect-deploy/#creating-work-pool-based-deployments-with-deploy).

To set up a long-lived process on a Windows machine the pattern is similar.
Instead of systemd, you can use [NSSM](https://nssm.cc/).
---
title: Prefect MCP Server
sidebarTitle: Prefect MCP Server
description: Connect AI assistants to your Prefect instance using the Model Context Protocol.
---

The Prefect MCP server enables AI assistants to interact with your Prefect workflows and infrastructure through the [Model Context Protocol (MCP)](https://modelcontextprotocol.io/). This integration allows AI tools like Claude Code, Cursor, and Codex CLI to help you monitor deployments, debug flow runs, query infrastructure, and more.

<Warning>
The Prefect MCP server is currently in beta. APIs, features, and behaviors may change without notice. We encourage you to try it out and provide feedback through [GitHub issues](https://github.com/PrefectHQ/prefect-mcp-server/issues).
</Warning>

## What is the Prefect MCP server?

The Prefect MCP server is an [MCP](https://modelcontextprotocol.io/) server that provides AI assistants with tools to:

- **Monitor & inspect**: View system health, query deployments, flow runs, task runs, work pools, and execution logs
- **Debug intelligently**: Get contextual guidance for troubleshooting failed flows and deployment issues
- **Access documentation**: Query up-to-date Prefect documentation through an integrated docs proxy

The MCP tools are primarily designed for reading data and monitoring your Prefect instance. For creating or updating resources, the integrated docs proxy provides AI assistants with current information on how to use the `prefect` CLI.

## Security considerations

The Prefect MCP server provides **read-only access** to your Prefect instance. It can only access information available to the account you authenticate with—it cannot access data outside those bounds.

<Warning>
**Important:** The MCP server does not operate in isolation. MCP clients (such as Claude Code, Cursor, or Codex CLI) may have additional capabilities beyond the MCP server's read-only tools. For example, an AI assistant with terminal access could execute destructive CLI commands like `prefect deployment delete` independently of the MCP server.

When using AI agents autonomously, consider the Prefect Role associated with your API key and what actions the agent could take through other means (CLI, SDK, etc.).
</Warning>

For detailed answers to common security questions—including authentication patterns, RBAC, file access requirements, and recommendations for internal pilots—see the [Security FAQ](https://github.com/PrefectHQ/prefect-mcp-server/blob/main/SECURITY.md).

## Prerequisites

Before installing the Prefect MCP server, ensure you have:

- **Python 3.9 or newer** (for `uvx`)
- **uv** installed (Python package installer): `pip install uv` or `curl -LsSf https://astral.sh/uv/install.sh | sh`
- **A Prefect instance**: Either [Prefect Cloud](https://app.prefect.cloud) or a self-hosted Prefect server
- **Prefect credentials**: API key (for Prefect Cloud) or configured profile in `~/.prefect/profiles.toml`

## Quick start

The fastest way to get started depends on your AI assistant:

<AccordionGroup>

<Accordion title="Claude Code" defaultOpen>

**Recommended: Use the marketplace**

```bash
/plugin marketplace add prefecthq/prefect-mcp-server
/plugin install prefect
```

This installs both the MCP server and a CLI skill for working with Prefect.

**Alternative: Manual setup**

```bash
# Uses your local Prefect profile from ~/.prefect/profiles.toml
claude mcp add prefect -- uvx --from prefect-mcp prefect-mcp-server
```

</Accordion>

<Accordion title="Cursor">

Add this configuration to `.cursor/mcp.json` in your project:

```json
{
  "mcpServers": {
    "prefect": {
      "command": "uvx",
      "args": ["--from", "prefect-mcp", "prefect-mcp-server"]
    }
  }
}
```

</Accordion>

<Accordion title="Codex CLI">

```bash
codex mcp add prefect -- uvx --from prefect-mcp prefect-mcp-server
```

</Accordion>

<Accordion title="Gemini CLI">

```bash
gemini mcp add prefect uvx --from prefect-mcp prefect-mcp-server
```

</Accordion>

</AccordionGroup>

## Test your setup

Once configured, try these prompts to verify the connection:

- "Show me my recent flow runs"
- "What deployments are available?"
- "Debug my last failed flow run"



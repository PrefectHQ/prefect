---
title: services
sidebarTitle: services
---

# `prefect.utilities.services`

## Functions

### `critical_service_loop` <sup><a href="https://github.com/PrefectHQ/prefect/blob/main/src/prefect/utilities/services.py#L21" target="_blank"><Icon icon="github" style="width: 14px; height: 14px;" /></a></sup>

```python
critical_service_loop(workload: Callable[..., Coroutine[Any, Any, Any]], interval: float, memory: int = 10, consecutive: int = 3, backoff: int = 1, printer: Callable[..., None] = print, run_once: bool = False, jitter_range: Optional[float] = None) -> None
```


Runs the given `workload` function on the specified `interval`, while being
forgiving of intermittent issues like temporary HTTP errors.  If more than a certain
number of `consecutive` errors occur, print a summary of up to `memory` recent
exceptions to `printer`, then begin backoff.

The loop will exit after reaching the consecutive error limit `backoff` times.
On each backoff, the interval will be doubled. On a successful loop, the backoff
will be reset.

**Args:**
- `workload`: the function to call
- `interval`: how frequently to call it
- `memory`: how many recent errors to remember
- `consecutive`: how many consecutive errors must we see before we begin backoff
- `backoff`: how many times we should allow consecutive errors before exiting
- `printer`: a `print`-like function where errors will be reported
- `run_once`: if set, the loop will only run once then return
- `jitter_range`: if set, the interval will be a random variable (rv) drawn from
a clamped Poisson distribution where lambda = interval and the rv is bound
between `interval * (1 - range) < rv < interval * (1 + range)`


### `start_client_metrics_server` <sup><a href="https://github.com/PrefectHQ/prefect/blob/main/src/prefect/utilities/services.py#L162" target="_blank"><Icon icon="github" style="width: 14px; height: 14px;" /></a></sup>

```python
start_client_metrics_server() -> None
```


Start the process-wide Prometheus metrics server for client metrics (if enabled
with `PREFECT_CLIENT_METRICS_ENABLED`) on the port `PREFECT_CLIENT_METRICS_PORT`.


### `stop_client_metrics_server` <sup><a href="https://github.com/PrefectHQ/prefect/blob/main/src/prefect/utilities/services.py#L177" target="_blank"><Icon icon="github" style="width: 14px; height: 14px;" /></a></sup>

```python
stop_client_metrics_server() -> None
```


Stop the process-wide Prometheus metrics server for client metrics, if it has
previously been started


---
title: Retrieve code from storage
description: Learn about where to store your flow code.
---

When a deployment runs, the execution environment needs access to the flow code.
Flow code is not stored in Prefect server or Prefect Cloud.

You have several flow code storage options for remote execution:
- Git-based storage (GitHub, GitLab, Bitbucket)
- Docker image-based storage
- Cloud-provider storage (AWS S3, Azure Blob Storage, GCP GCS)

Local storage is also an option for deployments that run locally.

For the examples below we show how to create a work pool-based deployment for each of these storage options. 
We show both the `prefect.yaml` configuration and the Python code needed to create the deployment.

Note that to create a prefect.yaml file interactively, you can run `prefect deploy` and select the appropriate storage option.

## Git-based storage

Git-based version control platforms provide redundancy, version control, and collaboration capabilities. Prefect supports:

- [GitHub](https://github.com/)
- [GitLab](https://www.gitlab.com)
- [Bitbucket](https://bitbucket.org/)

If you are using a private repository, we suggest creating a personal access token.

The process for creating access tokens differs for each provider.

<Tabs>
  <Tab title="GitHub">

    We recommend using HTTPS with [fine-grained Personal Access Tokens](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens#creating-a-fine-grained-personal-access-token) 
    to limit access by repository. 
    See the GitHub docs for [Personal Access Tokens (PATs)](https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token).

    Under *Your Profile -> Developer Settings -> Personal access tokens -> Fine-grained token* choose *Generate New Token* and 
    fill in the required fields. 
    Under *Repository access* choose *Only select repositories* and grant the token permissions for *Contents*.
  </Tab>
  <Tab title="Bitbucket">

    We recommend using HTTPS with Repository, Project, or Workspace [Access Tokens](https://support.atlassian.com/bitbucket-cloud/docs/access-tokens/). 
    
    You can create a Repository Access Token with Scopes -> Repositories -> Read.

    Bitbucket requires you prepend the token string with `x-token-auth:` The full string looks like 
    `x-token-auth:abc_123_this_is_a_token`. 
  </Tab>
  <Tab title="GitLab">

    We recommend using HTTPS with [Project Access Tokens](https://docs.gitlab.com/ee/user/profile/personal_access_tokens.html).

    In your repository in the GitLab UI, select *Settings -> Repository -> Project Access Tokens* and check 
    *read_repository* under *Select scopes*.
  </Tab>
</Tabs>

To configure a Secret block ahead of time and use it in your deployment, create the block in code or the Prefect UI and 
reference it in your `prefect.yaml` file `pull` step or your Python `deploy` method.

<CodeGroup>

```python my_private_gh_deploy_secret_block.py
from prefect import flow
from prefect.runner.storage import GitRepository
from prefect.blocks.system import Secret


if __name__ == "__main__":
    flow.from_source(
        source=GitRepository(
            url="https://github.com/org/my-private-repo.git",
            credentials=Secret.load("my-secret-block-with-my-gh-credentials")
        ),
        entrypoint="my_file.py:my_flow",
    ).deploy(
        name="private-github-deploy",
        work_pool_name="my_pool",
    )
```

```yaml prefect.yaml

pull:
    - prefect.deployments.steps.git_clone:
        repository: https://gitlab.com/org/my-private-repo.git
        access_token: "{{ prefect.blocks.secret.my-block-name }}"
```
</CodeGroup>

Alternatively, instead of creating a Secret block, you can create a Credentials block ahead of time and reference it in the `prefect.yaml` pull step or your Python `deploy` method.

<Tabs>
  <Tab title="GitHub">

    1. Install prefect-github with `pip install -U prefect-github`
    1. Register the blocks in that library to make them available on the server with `prefect block register -m prefect_github`
    1. Create a GitHub Credentials block through code or the Prefect UI and reference it at deployment creation as shown:

    <CodeGroup>

    ```python my_private_gh_deploy_credentials_block.py
    from prefect import flow
    from prefect.runner.storage import GitRepository
    from prefect_github import GitHubCredentials


    if __name__ == "__main__":
        flow.from_source(
            source=GitRepository(
            url="https://github.com/org/my-private-repo.git",
            credentials=GitHubCredentials.load("my-github-credentials-block")
        ),
        entrypoint="my_file.py:my_flow",
        ).deploy(
            name="private-github-deploy",
            work_pool_name="my_pool",
        )
    ```

    ```yaml prefect.yaml

    pull:
        - prefect.deployments.steps.git_clone:
            repository: https://github.com/org/my-private-repo.git
            credentials: "{{ prefect.blocks.github-credentials.my-github-credentials-block }}"
    ```
    </CodeGroup>
  </Tab>  
  <Tab title="Bitbucket">

    1. Install prefect-bitbucket with `pip install -U prefect-bitbucket`
    1. Register the blocks in that library with `prefect block register -m prefect_bitbucket` 
    1. Create a Bitbucket credentials block in code or the Prefect UI and reference at deployment creation as shown:

    <CodeGroup>

    ```python my_private_bb_deploy_credentials_block.py

    from prefect import flow
    from prefect.runner.storage import GitRepository
    from prefect_bitbucket import BitBucketCredentials


    if __name__ == "__main__":
        flow.from_source(
            source=GitRepository(
                url="https://bitbucket.com/org/my-private-repo.git",
                credentials=BitBucketCredentials.load("my-bitbucket-credentials-block")
            ),
        entrypoint="my_file.py:my_flow",
        ).deploy(
            name="private-bitbucket-deploy",
            work_pool_name="my_pool",
        )
    ```

    ```yaml prefect.yaml

    pull:
        - prefect.deployments.steps.git_clone:
            repository: https://bitbucket.org/org/my-private-repo.git
            credentials: "{{ prefect.blocks.bitbucket-credentials.my-bitbucket-credentials-block }}"
    ```
    </CodeGroup>
  </Tab>
<Tab title="GitLab">

    1. Install prefect-gitlab with `pip install -U prefect-gitlab`
    1. Register the blocks in that library with `prefect block register -m prefect_gitlab` 
    1. Create a GitLab credentials block in code or the Prefect UI and reference it at deployment creation as shown:

    <CodeGroup>

    ```python my_private_gl_deploy_credentials_block.py

    from prefect import flow
    from prefect.runner.storage import GitRepository
    from prefect_gitlab import GitLabCredentials


    if __name__ == "__main__":
        flow.from_source(
            source=GitRepository(
            url="https://gitlab.com/org/my-private-repo.git",
            credentials=GitLabCredentials.load("my-gitlab-credentials-block")
        ),
        entrypoint="my_file.py:my_flow",
        ).deploy(
            name="private-gitlab-deploy",
            work_pool_name="my_pool",
        )
    ```

    ```yaml prefect.yaml

    pull:
        - prefect.deployments.steps.git_clone:
            repository: https://gitlab.com/org/my-private-repo.git
            credentials: "{{ prefect.blocks.gitlab-credentials.my-gitlab-credentials-block }}"
    ```
    </CodeGroup>
  </Tab>
</Tabs>

<Warning>
**Push your code**

When you make a change to your code, Prefect does not push your code to your git-based version control platform.
You need to push your code manually or as part of your CI/CD pipeline.
This is intentional to avoid confusion about the git history and push process.
</Warning>

## Docker-based storage

Another popular flow code storage option is to include it in a Docker image. 
All work pool options except **Process** and **Prefect Managed** allow you to bake your code into a Docker image.

To create a deployment with Docker-based flow code storage use the Python `deploy` method or create a `prefect.yaml` file.
The `prefect.yaml` file below was generated by running `prefect deploy` from the CLI. 
A few lies of metadata were excluded from the top of the file output for brevity.

<CodeGroup>

```python my_docker_deploy.py
from prefect import flow

@flow
def my_flow():
    print("Hello from inside a Docker container!")

if __name__ == "__main__":
    my_flow.deploy(
        name="my-docker-deploy",
        work_pool_name="my_pool",
        image="my-docker-image:latest",
    )
```

```yaml prefect.yaml
# build section allows you to manage and build docker images
build:
- prefect_docker.deployments.steps.build_docker_image:
    requires: prefect-docker>=0.3.1
    id: build-image
    dockerfile: auto
    image_name: my_username/default
    tag: latest

# push section allows you to manage if and how this project is uploaded to remote locations
push: null

# pull section allows you to provide instructions for cloning this project in remote locations
pull:
- prefect.deployments.steps.set_working_directory:
    directory: /opt/prefect/my_directory


# the deployments section allows you to provide configuration for deploying flows
deployments:
- name: my-docker-deployment
  version: null
  tags: []
  concurrency_limit: null
  description: null
  entrypoint: my_file.py:my_flow
  parameters: {}
  work_pool:
    name: my_pool
    work_queue_name: null
    job_variables:
      image: '{{ build-image.image }}'
  enforce_parameter_schema: true
  schedules: []

- prefect.deployments.steps.git_clone:
    id: clone-step # needed to be referenced in subsequent steps
    repository: https://github.com/org/repo.git

```
</CodeGroup>

Any pip packages specified in a `requirements.txt` file will be included in the image.

In the examples above, we elected not to push the image to a remote registry.

To push the image to a remote registry, pass `push=True` in the Python `deploy` method or change `push: true` in the `prefect.yaml` file.

<Tip>
**CI/CD may not require push or pull steps**

You don't need push or pull steps in the `prefect.yaml` file if using CI/CD to build a Docker image outside of Prefect.
Instead, the work pool can reference the image directly.
</Tip>

## Cloud-provider storage

If you don't store your flow code in a git provider storage or a Docker image, you can store it in AWS S3, Azure Blob Storage, or GCP GCS.

If the storage location is publicly available or if you are authenticated in the environment where you are creating and running your deployment, you can reference the storage location directly. 

If you need to pass credentials explicitly to authenticate to your storage location, you can use any of the following block types:

- Prefect integration library storage block, such as the `prefect-aws` library's `S3Bucket` block.
- Prefect integration library credentials block, such as the `prefect-aws` library's `AwsCredentials` block 
- Secret block

Any of these options are valid for any cloud-provider storage option. 

The examples below show how to create a deployment with flow code stored in AWS S3. 

The `prefect.yaml` example shows the single line of code needed to reference an AWS Credentials block if using that to authenticate. 

<Tabs>
  <Tab title="AWS S3 bucket">

    <CodeGroup>

    ```python my_s3_deploy_no_credentials_passed_explicitly.py
    from prefect import flow


    if __name__ == "__main__":
        flow.from_source(
            source="s3://my-bucket/my-folder",
            entrypoint="my_file.py:my_flow",
        ).deploy(
            name="deployment-from-aws-flow",
            work_pool_name="my-work-pool",
        )
    ```

    ```python my_s3_deploy_credentials_s3bucket_block.py

    # example with an S3Bucket block (the S3Bucket block has a nested AWS Credentials block)
    from prefect import flow
    from prefect_aws.s3 import S3Bucket

    if __name__ == "__main__":
        flow.from_source(
            source=S3Bucket.load("my-code-storage-block"), entrypoint="my_file.py:my_flow"
        ).deploy(name="test-s3", work_pool_name="my-work-pool")
    ```

    ```python my_s3_deploy_credentials_aws_credentials_block.py
    # example with an AWS Credentials block
    from prefect import flow
    from prefect_aws import AwsCredentials

    if __name__ == "__main__":
        aws_credentials = AwsCredentials.load("my-credentials-block")
        flow.from_source(
            source="s3://my-bucket/my-folder",
            entrypoint="my_file.py:my_flow",
            credentials=aws_credentials
        ).deploy(
            name="aws-s3-deployment",
            work_pool_name="my-work-pool"
        )
    ```

    ```python my_s3_deploy_secret_block.py
    # example with AWS credentials stored in a Secret block
    from prefect import flow
    from prefect.blocks.system import Secret

    if __name__ == "__main__":
        flow.from_source(
            source="s3://my-bucket/my-folder",
            entrypoint="my_file.py:my_flow",
            credentials=Secret.load("my-secret-block-with-aws-credentials")
        ).deploy(
            name="aws-s3-deployment",
            work_pool_name="my-work-pool"
        )
    ```

    ```yaml prefect.yaml
    # push section allows you to manage if and how this project is uploaded to remote locations
    push:
    - prefect_aws.deployments.steps.push_to_s3:
        id: push_code
        requires: prefect-aws>=0.5
        bucket: my-bucket
        folder: my-folder
        credentials: "{{ prefect.blocks.aws-credentials.my-credentials-block }}" # if explicit authentication is required

    # pull section allows you to provide instructions for cloning this project in remote locations
    pull:
    - prefect_aws.deployments.steps.pull_from_s3:
        id: pull_code
        requires: prefect-aws>=0.5
        bucket: '{{ push_code.bucket }}'
        folder: '{{ push_code.folder }}'
        credentials: "{{ prefect.blocks.aws-credentials.my-credentials-block }}" # if explicit authentication is required 
    ``` 

    </CodeGroup>

    Here's step-by-step instructions for creating an AWS credentials block:

    1. Install the [Prefect-AWS](https://prefecthq.github.io/prefect-aws/) library with `pip install -U prefect-aws`
    1. Register the blocks in Prefect-AWS with `prefect block register -m prefect_aws` 
    1. Create a user with a role with read and write permissions to access the bucket. If using the UI, create an access key pair with *IAM -> Users -> Security credentials -> Access keys -> Create access key*. Choose *Use case -> Other* and then copy the *Access key* and *Secret access key* values.
    1. Create an [AWS Credentials block](nitegrations/prefect-aws/index#save-credentials-to-an-aws-credentials-block) in code or the Prefect UI. In addition to the block name, most users will fill in the *AWS Access Key ID* and *AWS Access Key Secret* fields.
    1. Reference the block as shown above.

  </Tab>
  <Tab title="Azure Blob Storage container">

    <CodeGroup>

    ```python my_azure_deploy.py
    from prefect import flow
    from prefect_azure import AzureBlobCredentials


    if __name__ == "__main__":
        flow.from_source(
            source=AzureBlobStorage(
                container="my-prefect-azure-container",
                folder="my-folder",
                credentials=AzureBlobCredentials.load("my-credentials-block")
            ),
            entrypoint="my_file.py:my_flow",
        ).deploy(
            name="my-deployment",
    )
    ```

    ```yaml prefect.yaml
    
    # push section allows you to manage if and how this project is uploaded to remote locations
    push:
    - prefect_azure.deployments.steps.push_to_azure_blob_storage:
        id: push_code
        requires: prefect-azure>=0.4
        container: my-prefect-azure-container
        folder: my-folder
        credentials: "{{ prefect.blocks.azure-blob-storage-credentials.my-credentials-block }}" # if private

    # pull section allows you to provide instructions for cloning this project in remote locations
    pull:
    - prefect_azure.deployments.steps.pull_from_azure_blob_storage:
        id: pull_code
        requires: prefect-azure>=0.4
        container: '{{ push_code.container }}'
        folder: '{{ push_code.folder }}'
        credentials: "{{ prefect.blocks.azure-blob-storage-credentials.my-credentials-block }}" # if private
    ```

    </CodeGroup>

    If the blob storage requires authentication to access it, follow these steps:

    1. Install the [prefect-azure](/integrations/prefect-azure/) library with `pip install -U prefect-azure`
    1. Register the blocks in prefect-azure with `prefect block register -m prefect_azure` 
    1. Create an access key for a role with sufficient (read and write) permissions to access the blob. 
    You can create a connection string containing all required information in the UI under *Storage Account -> Access keys*.
    1. Create an Azure Blob Storage Credentials block in code or the Prefect UI. Enter a name for the block and paste the 
    connection string into the *Connection String* field.
    1. Reference the block as shown in the push and pull steps above.
  </Tab>
  <Tab title="GCP GCS bucket">

    Choose `GCS` as the recipe and enter the bucket name when prompted.

    <CodeGroup>

    ```python my_gcs_deploy.py
    from prefect import flow
    from prefect_gcp import GCSBucketCredentials


    if __name__ == "__main__":
        flow.from_source(
            source=GCSBucket(
                bucket="my-bucket",
                folder="my-folder",
                credentials=GCSBucketCredentials.load("my-credentials-block")
            ),
            entrypoint="my_file.py:my_flow",
        ).deploy(
            name="my-deployment",
            work_pool_name="my_pool"
        )
    ```

    ```yaml prefect.yaml
    # push section allows you to manage if and how this project is uploaded to remote locations
    push:
    - prefect_gcp.deployment.steps.push_to_gcs:
        id: push_code
        requires: prefect-gcp>=0.6
        bucket: my-bucket
        folder: my-folder
        credentials: "{{ prefect.blocks.gcp-credentials.my-credentials-block }}" # if private 

    # pull section allows you to provide instructions for cloning this project in remote locations
    pull:
    - prefect_gcp.deployment.steps.pull_from_gcs:
        id: pull_code
        requires: prefect-gcp>=0.6
        bucket: '{{ push_code.bucket }}'
        folder: '{{ pull_code.folder }}'
        credentials: "{{ prefect.blocks.gcp-credentials.my-credentials-block }}" # if private 
    ```
    </CodeGroup>
    
    If the bucket requires authentication to access it, follow these steps:

    1. Install the [Prefect-GCP](/integrations/prefect-gcp/) library with `pip install -U prefect-gcp`
    1. Register the blocks in Prefect-GCP with `prefect block register -m prefect_gcp` 
    1. Create a service account in GCP for a role with read and write permissions to access the bucket contents. 
    If using the GCP console, go to *IAM & Admin -> Service accounts -> Create service account*. 
    After choosing a role with the required permissions, 
    see your service account and click on the three dot menu in the *Actions* column. 
    Select *Manage Keys -> ADD KEY -> Create new key -> JSON*. Download the JSON file.
    1. Create a GCP Credentials block in code or the Prefect UI. Enter a name for the block and paste the entire contents of the JSON key file into the *Service Account Info* field.
    1. Reference the block as shown in the push and pull steps above.
    </Tab>
</Tabs>

Another authentication option is to give the [worker](/3.0/deploy/infrastructure-concepts/workers/) access to the storage location at runtime through SSH keys.

Note that you can inject environment variables into a `prefect.yaml` deployment specification.

## Store code locally

If you are using a Process work pool, you can store your flow code in a local folder.

<CodeGroup>

```python
from prefect import flow
from pathlib import Path


@flow(log_prints=True)
def my_flow(name: str = "World"):
    print(f"Hello {name}!")
    print(str(Path(__file__).parent))  # dynamic path


if __name__ == "__main__":
    my_flow.from_source(
        source=str(Path(__file__).parent),  # code stored in local directory
        entrypoint="local_process_deploy_local_code.py:my_flow",
    ).deploy(
        name="local-process-deploy-local-code",
        work_pool_name="process-pool",
    )
```

```yaml prefect.yaml  # TK add

pull:
    - prefect.deployments.steps.local_file_copy:
        source: /path/to/destination
        destination: ./my_folder
```
</CodeGroup>

## Include or exclude files from storage

By default, Prefect includes all files in the current folder when you create a deployment.

When using a git repository, Docker image, or cloud-provider storage location, you may want to exclude certain files or directories. If you are familiar with Docker you are likely familiar with the [`.dockerignore`](https://docs.docker.com/engine/reference/builder/#dockerignore-file) file. For cloud-provider storage, the `.prefectignore` file serves the same purpose and follows a similar syntax as those files. So an entry of `*.pyc` will exclude all `.pyc` files from upload.





TK from here down was just taken from the docker page and needs integrated.

The `entrypoint` is the path to the file the flow is located in and the function name, separated by a colon.

Alternatively, you could specify a git-based cloud storage URL for a Bitbucket or GitLab repository.



After creating a deployment, you may need to change your flow code.
Generally, you can just push your code to GitHub, without rebuilding your deployment.
The exception is if there is something the server needs to know about changes, such as the flow entrypoint parameters.
Rerunning the Python script with `.deploy` updates your deployment on the server with the new flow code.

If you need to provide additional configuration, such as specifying a private repository, you can provide a
[`GitRepository`](https://prefect-python-sdk-docs.netlify.app/prefect/flows/#prefect.runner.storage.GitRepository) object instead of a URL:

```python private_git_storage.py
from prefect import flow
from prefect.runner.storage import GitRepository
from prefect.blocks.system import Secret

if __name__ == "__main__":
    flow.from_source(
        source=GitRepository(
            url="https://github.com/org/private-repo.git",
            branch="dev",
            credentials={
                "access_token": Secret.load("github-access-token")
            }
        ),
        entrypoint="flows/no-image.py:hello_world",
    ).deploy(
        name="private-git-storage-deployment",
        work_pool_name="my-docker-pool",
        build=False
    )
```

Note the use of the Secret block to load the GitHub access token.
Alternatively, you could provide a username and password to the `username` and `password` fields of the `credentials` argument.



Another option for flow code storage is any [fsspec](https://filesystem-spec.readthedocs.io/en/latest/)-supported
storage location, such as AWS S3, GCP GCS, or Azure Blob Storage.

For example, you can pass the S3 bucket path to `source`.




In the example above, your credentials are auto-discovered from your deployment creation environment. Your credentials
must be available in your runtime environment.

If you need additional configuration for your cloud-based storage (for example, with a private S3 Bucket), we recommend using a
[storage block](/3.0/develop/blocks/).


A storage block also ensures your credentials are available in both your deployment creation environment and your execution
environment.



### Flow code storage for deployments created with `.serve` 

Recall that `.serve` is a way to create a deployment and a local long-running process to poll for flow runs at the same time.

The deployment creation mechanics for `.serve` are similar to `.deploy`. 
`.deploy`just requires a work pool name and has a number of parameters dealing with flow code storage for Docker images.

Unlike `.serve`, if you don't specify an image to use for your flow, you must specify where to pull the flow code from at runtime with the `from_source` method; `from_source` is optional with `.serve`.
